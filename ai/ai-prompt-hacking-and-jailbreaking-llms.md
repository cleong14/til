---
title: 2024-05-01 - TIL - AI Prompt Hacking and Jailbreaking LLMs
date: 2024-05-01 16:43:55
tags: [ai-prompt-hacking-and-jailbreaking-llms, resources, til]
aliases: [today-i-learned, things-i-learned]
---


# 2024-05-01 - TIL - AI Prompt Hacking and Jailbreaking LLMs

Resources on AI Prompt Hacking and Jailbreaking LLMs.


## Exercises

- [Test your prompting skills to make Gandalf reveal secret information](https://gandalf.lakera.ai/)
- [Predecessor of the Gandalf Exercise](https://gpa.43z.one/)


## Slides

- [LLM Threats: Prompt Injections and Jailbreak Attacks](https://www.slideshare.net/slideshow/llm-threats-prompt-injections-and-jailbreak-attacks/267009309)
- [A Primer on LLM Security: Hacking Large Language Models for Beginners](https://docs.kleiber.me/2023-12-29-Kleiber-A-Primer-On-LLM-Security.pdf)
- ["I want a slide deck on an intro to jailbreaking LLMs and prompt hacking" - SlidesGPT AI Generated PowerPoint](https://slidesgpt.com/l/3wmR)


## Learning Resources

- [Prompt Injection](https://learnprompting.org/docs/prompt_hacking/injection)
- [Prompt Leaking](https://learnprompting.org/docs/prompt_hacking/leaking)
- [Jailbreaking](https://learnprompting.org/docs/prompt_hacking/jailbreaking)


## Use Cases

- Learn about AI Prompt Hacking and Jailbreaking LLMs
- Practice applying what you've learned in a safe, secure, and legal way


## References

- [Learn Prompting: Your Guide to Communicating with AI](https://learnprompting.org/)
- [SlidesGPT AI PowerPoint Generator Powered by ChatGPT API](https://slidesgpt.com/)
- [Vulnerable LLM Applications Â· OWASP/www-project-top-10-for-large-language-model-applications Wiki](https://github.com/OWASP/www-project-top-10-for-large-language-model-applications/wiki/Vulnerable-LLM-Applications)
- [OWASP Top 10 for Large Language Model Applications | OWASP Foundation](https://owasp.org/www-project-top-10-for-large-language-model-applications/)


